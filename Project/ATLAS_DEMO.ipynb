{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRSV3bJaWYfR"
      },
      "source": [
        "\n",
        "### [1] SSH onto the HPC\n",
        "\n",
        "`ssh SJSU_ID@coe-hpc1.sjsu.edu`\n",
        "\n",
        "### [2] Clone Atlas to your home directory\n",
        "\n",
        "`git clone https://github.com/facebookresearch/atlas.git`\n",
        "\n",
        "### [3] Copy files from /data to atlas_data folder\n",
        "##### Ideally, you need the 10 million passage dataset for retrieval, and the nq_data folder\n",
        "\n",
        "`cp /data/cmpe259-fa23/atlas_data/corpora/wiki/enwiki-dec2018/text-list-10mil.jsonl /home/SJSU_ID/atlas/atlas_data/corpora/wiki/enwiki-dec2018/text-list-10mil.jsonl` \n",
        "\n",
        "`cp -r /data/cmpe259-fa23/atlas_data/nq_data /home/SJSU_ID/atlas/atlas_data/`\n",
        "\n",
        "`cp -r /data/cmpe259-fa23/atlas_data/models/ /home/SJSU_ID/atlas/atlas_data`\n",
        "\n",
        "### [4] Change directory to Atlas\n",
        "\n",
        "`cd atlas`\n",
        "\n",
        "### [5] Load Python 3.8.8\n",
        "\n",
        "`module load python3/3.8.8`\n",
        "\n",
        "### [6] Install Requirements \n",
        "\n",
        "##### TORCH with CUDA \n",
        "\n",
        "`pip3 install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113`\n",
        "\n",
        "\n",
        "##### requirements.txt file\n",
        "\n",
        "`pip3 install -r requirements.txt`\n",
        "\n",
        "### [7] Copy the below batch script and save as atlas_demo.sh\n",
        "\n",
        "#### Update necessary fields SJSU ID, home directory location etc. accordingly. Make sure Job name contains your SJSU ID \n",
        "\n",
        "```\n",
        "#!/bin/bash\n",
        "#SBATCH --mail-user=SJSU_EMAIL@sjsu.edu\n",
        "#SBATCH --mail-user=/dev/null\n",
        "#SBATCH --mail-type=BEGIN,END,FAIL\n",
        "#SBATCH --job-name=gpuTest_SJSU_ID\n",
        "#SBATCH --output=gpuTest_%j.out\n",
        "#SBATCH --error=gpuTest_%j.err\n",
        "#SBATCH --ntasks=1\n",
        "#SBATCH --cpus-per-task=1\n",
        "#SBATCH --time=48:00:00     \n",
        "##SBATCH --mem-per-cpu=2000\n",
        "##SBATCH --gres=gpu:p100:1\n",
        "#SBATCH --partition=gpu   \n",
        "\n",
        "# on coe-hpc1 cluster load\n",
        "# module load python3/3.8.8\n",
        "#\n",
        "# on coe-hpc2 cluster load:\n",
        "module load python-3.10.8-gcc-11.2.0-c5b5yhp slurm\n",
        "\n",
        "export http_proxy=http://172.16.1.2:3128; export https_proxy=http://172.16.1.2:3128\n",
        "\n",
        "cd /home/SJSU_ID/atlas\n",
        "\n",
        "DATA_DIR=/home/SJSU_ID/atlas/atlas_data\n",
        "port=$(shuf -i 15000-16000 -n 1)\n",
        "TRAIN_FILE=\"${DATA_DIR}/nq_data/train.64-shot.jsonl\"\n",
        "EVAL_FILES=\"${DATA_DIR}/nq_data/dev.jsonl\"\n",
        "SAVE_DIR=${DATA_DIR}/experiments/\n",
        "EXPERIMENT_NAME=my_ten_mil_exp\n",
        "TRAIN_STEPS=30\n",
        "\n",
        "\n",
        "# submit your code to Slurm \n",
        "python3 /home/SJSU_ID/atlas/train.py --shuffle  --train_retriever  --gold_score_mode pdist   --use_gradient_checkpoint_reader --use_gradient_checkpoint_retriever  --precision bf16   --shard_optim --shard_grads   --temperature_gold 0.01   --refresh_index -1   --query_side_retriever_training  --target_maxlength 16   --reader_model_type google/t5-base-lm-adapt --dropout 0.1 --weight_decay 0.01 --lr 4e-5 --lr_retriever 4e-5 --scheduler linear   --text_maxlength 256   --model_path \"/home/SJSU_ID/atlas/atlas_data/models/atlas/base/\"  --train_data \"${DATA_DIR}/nq_data/train.64-shot.jsonl\"   --eval_data \"${DATA_DIR}/nq_data/dev.jsonl\"   --per_gpu_batch_size 1  --n_context 10   --retriever_n_context 10   --name my_ten_mil_exp   --checkpoint_dir ${SAVE_DIR}   --eval_freq 30   --log_freq 4   --total_steps ${TRAIN_STEPS}   --warmup_steps 5  --save_freq ${TRAIN_STEPS}   --main_port $port   --write_results   --task qa   --index_mode flat   --passages \"/home/SJSU_ID/atlas/atlas_data/corpora/wiki/enwiki-dec2018/text-list-10mil.jsonl\"  --save_index_path ${SAVE_DIR}/${EXPERIMENT_NAME}/saved_index \n",
        "```\n",
        "\n",
        "### [8] SSH to coe-hpc2\n",
        "\n",
        "`ssh coe-hpc2`\n",
        "\n",
        "### [9] Run the batch script through slurm \n",
        "\n",
        "`cd atlas`\n",
        "`sbatch atlas_demo.sh`\n",
        "\n",
        "### [10] Check status of your job through squeue\n",
        "\n",
        "`squeue`\n",
        "`squeue -u SJSU_ID`\n",
        "\n",
        "### [11] Check log files \n",
        "\n",
        "`cat gpuTest_%j.out`\n",
        "\n",
        "### [12] Check experiment run log \n",
        "\n",
        "` cat /home/SJSU_ID/atlas/atlas_data/experiments/my_ten_mil_exp/run.log`\n",
        "\n",
        "### [13] After code execution, check result file\n",
        "\n",
        "`head -100 /home/015292108/atlas/atlas_data/experiments/my_ten_mil_exp/dev-step-30.jsonl`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6TZJy6mXamR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
